{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2fec48",
   "metadata": {},
   "source": [
    "This can be [run on Google Colab using this link](https://colab.research.google.com/github/CS7150/CS7150-Homework-3/blob/main/HW3.2-Generative_DAE.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8609c",
   "metadata": {},
   "source": [
    "# Generating Images with Denoising Autoencoder\n",
    "\n",
    "In this homework, let's see how one can generate samples from a denoising autoencoder (DAE).\n",
    "\n",
    "More info on DAE:\n",
    "1. Good article on various autoencoders [Link](https://towardsdatascience.com/autoencoders-and-the-denoising-feature-from-theory-to-practice-db7f7ad8fc78) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188be37",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder (DAE)\n",
    "\n",
    "Denoising Autoencoders are a class of autoencoders where we attempt to remove noise from a customized data. Note the emphasis on the word `customized`. Given that we train a DAE on a particular dataset, it is optimized to remove dataset from the samples of that dataset only and will not be suitable on other dataset samples. (Want to learn more on EBM models? Read more on [Energy Based Models](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf))\n",
    "\n",
    "So let's code a simple DAE and explore it's functioning !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split,Subset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading mnist into folder\n",
    "data_dir = 'data' # make sure that this folder is created in your working dir\n",
    "# transform the PIL images to tensor using torchvision.transform.toTensor method\n",
    "train_data = torchvision.datasets.MNIST(data_dir, train=True, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
    "test_data  = torchvision.datasets.MNIST(data_dir, train=False, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]))\n",
    "print(f'Datatype of the dataset object: {type(train_data)}')\n",
    "# check the length of dataset\n",
    "print(f'Number of samples in training data: {len(train_data)}')\n",
    "print(f'Number of samples in test data: {len(test_data)}')\n",
    "# Check the format of dataset\n",
    "print(f'Foramt of the dataset: \\n {train_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99254a83",
   "metadata": {},
   "source": [
    "## Displaying the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc391699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2, 3, i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(train_data[i][0][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Class Label: {}\".format(train_data[i][1]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d0f8f",
   "metadata": {},
   "source": [
    "## Building a DAE\n",
    "We are going to build the DAE a little different this time. We are going to separately build the encoder and decoder and then call a model that connects them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c60adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self, encoded_dim=4, hidden_lin_dim=128,device='cuda'):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc_conv1  = nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=2,padding=1) # output shape 8x16x16\n",
    "        self.enc_conv2  = nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=2,padding=1) # output shape 16x8x8\n",
    "        self.enc_conv3  = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=2,padding=0) # output shape 32x3x3\n",
    "        # Encoder Flatten\n",
    "        self.enc_flat   = nn.Flatten(start_dim=1)\n",
    "        self.enc_lin1   = nn.Linear(in_features=32*3*3, out_features=hidden_lin_dim) \n",
    "        self.enc_lin2   = nn.Linear(in_features=hidden_lin_dim, out_features=encoded_dim) \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        # encoder\n",
    "        ## block1\n",
    "        x = self.enc_conv1(inp)\n",
    "        x = nn.ReLU()(x)\n",
    "        ## block2\n",
    "        x = self.enc_conv2(x)\n",
    "        x = nn.BatchNorm2d(16,device=device)(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        ## block3\n",
    "        x = self.enc_conv3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        ## Flatten the encoding\n",
    "        x = self.enc_flat(x)\n",
    "        x = self.enc_lin1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.enc_lin2(x)\n",
    "        return x\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self, encoded_dim=4, hidden_lin_dim=128,device='cuda'):\n",
    "        super().__init__()\n",
    "        # Decoder Flatten\n",
    "        self.dec_lin1   = nn.Linear(in_features=encoded_dim, out_features=hidden_lin_dim) \n",
    "        self.dec_lin2   = nn.Linear(in_features=hidden_lin_dim, out_features=32*3*3)\n",
    "        self.dec_unflat = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
    "        # Decoder\n",
    "        self.dec_conv1 = nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, output_padding=0)\n",
    "        self.dec_conv2 = nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.dec_conv3 = nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "    def forward(self,inp):\n",
    "        # decoder\n",
    "        ## Flatenned decoding\n",
    "        x = self.dec_lin1(inp)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dec_lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dec_unflat(x)\n",
    "        ## block1\n",
    "        x = self.dec_conv1(x)\n",
    "        x = nn.BatchNorm2d(16,device=device)(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        ## block2\n",
    "        x = self.dec_conv2(x)\n",
    "        x = nn.BatchNorm2d(8,device=device)(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        ## block3\n",
    "        x = self.dec_conv3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3296402",
   "metadata": {},
   "source": [
    "## Function to add noise to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(inp,noise_factor=0.3):\n",
    "    noise = torch.rand(inp.shape) # Creating a noise in the same shape as input \n",
    "    noisy_image = inp + noise \n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d887b",
   "metadata": {},
   "source": [
    "## Functions to train and test the DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def train_dae(enc, dec, device, dataloader, loss_fn, optimizer,noise_factor=0.3):\n",
    "    # Set the models to train\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    # Initiate a loss monitor\n",
    "    train_loss = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning and not supervised classification)\n",
    "    for images, labels in dataloader: # the variable `labels` willbe used for customised training\n",
    "        # Add noise to images\n",
    "        noisy = add_noise(images, noise_factor)\n",
    "        # move the data to preferred device GPU/CPU\n",
    "        images = images.to(device)\n",
    "        noisy = noisy.to(device)    \n",
    "        # send the noisy data through DAE to denoise\n",
    "        ## encode the noisy image\n",
    "        encoded = enc(noisy)\n",
    "        ## decode the data to generate denoised image\n",
    "        denoised_images = dec(encoded)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(denoised_images, images)\n",
    "        # Backward pass (back propagation)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9384d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Function\n",
    "def test_dae(enc, dec, device, dataloader, loss_fn,noise_factor=0.3):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        denoised = []\n",
    "        actual = []\n",
    "        for images, labels in dataloader:\n",
    "            # Add noise to images\n",
    "            noisy = add_noise(images, noise_factor)\n",
    "            # move the data to preferred device GPU/CPU\n",
    "            images = images.to(device)\n",
    "            noisy = noisy.to(device)    \n",
    "            # send the noisy data through DAE to denoise\n",
    "            ## encode the noisy image\n",
    "            encoded = enc(noisy)\n",
    "            ## decode the data to generate denoised image\n",
    "            denoised_images = dec(encoded)\n",
    "            # Append the network output and the original image to the lists\n",
    "            denoised.append(denoised_images.cpu())\n",
    "            actual.append(images.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        denoised = torch.cat(denoised)\n",
    "        actual = torch.cat(actual) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(denoised, actual)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b356e",
   "metadata": {},
   "source": [
    "## Function to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279efc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dae_inference(encoder, decoder, test_dataset, n=10, noise_factor=0.3):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    labels = test_dataset.targets.numpy()\n",
    "    idx = {i:np.where(labels==i)[0][0] for i in range(n)}    \n",
    "    for i in range(n):\n",
    "\n",
    "        ax = plt.subplot(3,n,i+1)\n",
    "        ax.set(facecolor = \"white\")\n",
    "        image = test_dataset[idx[i]][0].unsqueeze(0)\n",
    "        noisy = add_noise(image, noise_factor)     \n",
    "        noisy = noisy.to(device)\n",
    "\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            denoised_image  = decoder(encoder(noisy))\n",
    "\n",
    "        plt.imshow(image.cpu().squeeze().numpy(), cmap='gray')\n",
    "        ax.axis('off')  \n",
    "        if i == n//2:\n",
    "            ax.set_title('Actual Image')\n",
    "        ax = plt.subplot(3, n, i + 1 + n)\n",
    "        plt.imshow(noisy.cpu().squeeze().numpy(), cmap='gray')\n",
    "        ax.axis('off')  \n",
    "        if i == n//2:\n",
    "            ax.set_title('Corrupted Image')\n",
    "\n",
    "        ax = plt.subplot(3, n, i + 1 + n + n)\n",
    "        plt.imshow(denoised_image.cpu().squeeze().numpy(), cmap='gray')  \n",
    "        ax.axis('off')   \n",
    "        if i == n//2:\n",
    "            ax.set_title('Denoised Image')\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.7, \n",
    "                    top=0.9, \n",
    "                    wspace=0.3, \n",
    "                    hspace=0.3)     \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6aea08",
   "metadata": {},
   "source": [
    "## Initializing the models, optimizer and loss function. Load the model to CPU/GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "# Choosing a device based on the env and torch setup\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "\n",
    "### Initialize the two networks\n",
    "encoded_dim = 4\n",
    "hidden_lin_dim = 128\n",
    "\n",
    "enc = encoder(encoded_dim=encoded_dim, hidden_lin_dim=hidden_lin_dim, device=device)\n",
    "dec = decoder(encoded_dim=encoded_dim, hidden_lin_dim=hidden_lin_dim, device=device)\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "enc.to(device)\n",
    "dec.to(device)\n",
    "\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': enc.parameters()},\n",
    "    {'params': dec.parameters()}\n",
    "]\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr= 0.001\n",
    "\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ccd7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Intialize dataloaders\n",
    "val_split = .2\n",
    "batch_size=256 \n",
    "include_samples = [0,1,2,3,4] # to ensure customised training\n",
    "\n",
    "indices = [idx for idx, target in enumerate(train_data.targets) if target in include_samples]\n",
    "train_data_new = Subset(train_data, indices) # Only include samples\n",
    "n_train_samples = len(train_data_new)\n",
    "train_data_, val_data = random_split(train_data_new, [int(n_train_samples*(1-val_split)), int(n_train_samples*val_split)+1])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data_, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "### Training cycle\n",
    "noise_factor = 0.3\n",
    "num_epochs = 30\n",
    "history={'train_loss':[],'val_loss':[]}\n",
    "\n",
    "print('DAE training started')\n",
    "for epoch in range(num_epochs):\n",
    "    ### Training \n",
    "    print(f'---------------------------------------------Epoch {epoch+1}/{num_epochs}---------------------------------------------')\n",
    "    train_loss=train_dae(\n",
    "        enc=enc, \n",
    "        dec=dec, \n",
    "        device=device, \n",
    "        dataloader=train_loader,\n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim,noise_factor=noise_factor)\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_dae(\n",
    "        enc=enc, \n",
    "        dec=dec, \n",
    "        device=device, \n",
    "        dataloader=valid_loader, \n",
    "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
    "    # Print Validationloss\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    print('\\n \\t \\t \\t train loss {:.3f} \\t val loss {:.3f}'.format(train_loss,val_loss))\n",
    "    plot_dae_inference(enc,dec,test_dataset=test_data,noise_factor=noise_factor)\n",
    "print('DAE training done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2528d41",
   "metadata": {},
   "source": [
    "So far we have repeated the DAE training from hw2.2. Now let's start the exercise of generating MNIST samples from DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e94359",
   "metadata": {},
   "source": [
    "## Can you generate from DAE?\n",
    "\n",
    "Exercise 3.2.1: We have a trained DAE model that was trained on subset of MNIST. Use the trained decoder to generate samples. How? Follow these steps:\n",
    "- Set the models to eval\n",
    "- with torch.no_grad, take a few samples from test dataloader and pass through encoder\n",
    "- Calculate the mean and standard deviation of the output of the encoder \n",
    "- Generate some random numbers (of size 100) with mean and std from above\n",
    "- Pass the random numbers through the decoder and display 10 of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set both the encoder and decoder to eval\n",
    "\n",
    "# take some images from test_loader (hint: use `iter`)\n",
    "\n",
    "# Pass them through encoder\n",
    "\n",
    "# Calculate mean and std of the output\n",
    "\n",
    "# Generate random numbers with mean and std from above step\n",
    "\n",
    "# Pass through decoder\n",
    "\n",
    "# Display the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1d284",
   "metadata": {},
   "source": [
    "Exercise 3.2.2: Now generate in the same way as above, except when you generate some random numbers use a very different mean and std (eg: 7 $\\times$ mean and 8 $\\times$ std). Show the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de87718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set both the encoder and decoder to eval\n",
    "\n",
    "# take some images from test_loader (hint: use `iter`)\n",
    "\n",
    "# Pass them through encoder\n",
    "\n",
    "# Calculate mean and std of the output\n",
    "\n",
    "# Generate random numbers with different mean and std from above step (eg: 7*mean and 8*std)\n",
    "\n",
    "# Pass through decoder\n",
    "\n",
    "# Display the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ecda67",
   "metadata": {},
   "source": [
    "What are your observations about the samples generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1342a95",
   "metadata": {},
   "source": [
    "## Diversity in Generations\n",
    "In this exercise, we will check how well our generated samples are distributed. In other words, we are going to check the classes generated by our model. Is it generating certain classes more or is it very well distributed. We are going to classify our outputs using a pretrained MNIST classifier that is opensourced. Why? Because you generated these samples from random numbers, we do not have labels for them. So let's get deep neural nets to do the work of counting the classes for us!\n",
    "\n",
    "Pretrained MNSIT classification model from [ML CS Tsinghua](https://github.com/aaron-xichen/pytorch-playground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066643b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class MNIST_Classifier(nn.Module):\n",
    "    '''\n",
    "    Pretrained model by  ML CS Tsinghua's Aaron et al.(https://github.com/aaron-xichen/pytorch-playground)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(MNIST_Classifier, self).__init__()\n",
    "        self.input_dims = 784\n",
    "        self.n_classes = 10\n",
    "        current_dims = self.input_dims\n",
    "        layers = OrderedDict()\n",
    "        n_hiddens = [256,256]\n",
    "        for i, n_hidden in enumerate(n_hiddens):\n",
    "            layers['fc{}'.format(i+1)] = nn.Linear(current_dims, n_hidden)\n",
    "            layers['relu{}'.format(i+1)] = nn.ReLU()\n",
    "            layers['drop{}'.format(i+1)] = nn.Dropout(0.2)\n",
    "            current_dims = n_hidden\n",
    "        layers['out'] = nn.Linear(current_dims, self.n_classes)\n",
    "\n",
    "        self.model= nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), -1)\n",
    "        assert input.size(1) == self.input_dims\n",
    "        return self.model.forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8484a5",
   "metadata": {},
   "source": [
    "<b>Exercise 3.2.3:</b> Use the generated images from above (from exercise 3.2.1) and run them through `evaluate_samples_classify` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb12b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the classfication model above and classify all the generated images (for this exercise generate 1000 samples)\n",
    "\n",
    "# Call the `MNIST_Classifier` model. \n",
    "\n",
    "# Load the pre-trained weights given to you along with this homework ('mnist_classify.pth') [hint: check out load_state_dict]\n",
    "\n",
    "# predict the class [Hint: Look for the maximum value of output.]\n",
    "\n",
    "# For each class predicted, plot the number of samples. For example, your classifier found 20 out of 1000 samples as class '9'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058a866",
   "metadata": {},
   "source": [
    "<b> Extra Credit (Optional)</b>\n",
    "\n",
    "If you have finished the above exercises, you will get full credit! This one is for extra credit.\n",
    "\n",
    "Visualizing the random latent space responsible for generation. Read the instructions completely before starting\n",
    "- Take some MNIST images (20, 2 per each class). Pass through encoder. Store the encoded samples\n",
    "- Generate some random numbers(20) and pass through decoder. Store the random numbers as they are the encodings to the generated images.\n",
    "- Generate some bad random number(20) and pass through decoder. Store the random numbers.\n",
    "- Now visualize these encoded representations. How? If their size were 2, you could have plotted them on scatter plot. That's something you can do in 2 ways.\n",
    "    - Build the encoder and decoder, but this time with encoding dimension as 2 instead of 4. Then plot them as scatter plot. To distinguish them, use markers and colors. \n",
    "    - Use the same models, except the saved encoded representations are size 4 arrays. So use t-SNE to reduce dimensions to 2. Plot the reduced representation. (Minimal coding to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999baea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
